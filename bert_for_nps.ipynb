{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_for_nps.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+gnNxr3sM8lkkMYhyTuvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b1a325055db46e0a921b2743f9b16f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a549297ef14143438119da1cde91da0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d5069a6a03f42e1a8fc5863ff2a90de",
              "IPY_MODEL_0336080f72bb47b8aa4b4a3880fafc8a"
            ]
          }
        },
        "a549297ef14143438119da1cde91da0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d5069a6a03f42e1a8fc5863ff2a90de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57d920cec519442b84d980632502520a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_644d5ffcb373492f98fbe5751f1ccc4f"
          }
        },
        "0336080f72bb47b8aa4b4a3880fafc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5ec939b26ca46a8b634ee58f01ca4b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 355kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff181e0d95cd4a1a9a6bd495f4d404d1"
          }
        },
        "57d920cec519442b84d980632502520a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "644d5ffcb373492f98fbe5751f1ccc4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5ec939b26ca46a8b634ee58f01ca4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff181e0d95cd4a1a9a6bd495f4d404d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7168abd443dc4939bb96d33424c6a501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1f3e3bd66194c2898e63dbe4431bede",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f62051068c4d490f9d10dd376b5e8d26",
              "IPY_MODEL_30f8a1916f0f4c25b418ec62bd40d681"
            ]
          }
        },
        "f1f3e3bd66194c2898e63dbe4431bede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f62051068c4d490f9d10dd376b5e8d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b896661e1a14ad78959e1288feb8f32",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_962ae8075b074fb28cc97eba94f64da5"
          }
        },
        "30f8a1916f0f4c25b418ec62bd40d681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_372fa204063e41f788935ffc9bfbe436",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 8.34kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9367c8a112464ab28a02a7a6bacf1a1a"
          }
        },
        "2b896661e1a14ad78959e1288feb8f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "962ae8075b074fb28cc97eba94f64da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "372fa204063e41f788935ffc9bfbe436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9367c8a112464ab28a02a7a6bacf1a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a0992b00178475fa91388992d81113f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7636475c736b4ece803783f8240ab526",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51377bf609884e08aa4f756ff38a9e65",
              "IPY_MODEL_9c416fc1723f4aba988da18fd0ac6793"
            ]
          }
        },
        "7636475c736b4ece803783f8240ab526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51377bf609884e08aa4f756ff38a9e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1d78937e7de4573a513e0caebf883f2",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15535af5f77f40f59e8f6603074dd79f"
          }
        },
        "9c416fc1723f4aba988da18fd0ac6793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc06914a72fc44c49d1c81e16c97bfe1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:41&lt;00:00, 10.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e10739852ae44349add845cd64374cc0"
          }
        },
        "e1d78937e7de4573a513e0caebf883f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15535af5f77f40f59e8f6603074dd79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc06914a72fc44c49d1c81e16c97bfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e10739852ae44349add845cd64374cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vtishenko/bert-nps-comments-classifier/blob/master/bert_for_nps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--C6UVeiCFGM",
        "colab_type": "text"
      },
      "source": [
        "## Imports & Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Iu59veYGNN",
        "colab_type": "code",
        "outputId": "7ca4984e-9c83-4658-9464-d43d8a4fd66d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHa-GwsgeFb_",
        "colab_type": "code",
        "outputId": "489ab03d-181e-4579-95c1-f60b502187e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 35.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 33.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 21.6MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 24.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 19.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 31.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 38.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 47.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 54.0MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 58.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 60.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 60.0MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 61.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 62.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 63.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 63.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 63.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 63.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 63.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 63.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 63.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 55.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=f48bcbc08c5f9983666d01509cbf5e69ff8ea945fe44af5e4a1121a2f0154b82\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh1QO-YjfYBn",
        "colab_type": "code",
        "outputId": "51d2ec79-5b81-446d-98dd-26616e7e028d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=57f287d6d958c7f5d3398c238bd74f0620bbd6ad546a5d66c56f8f0bfa8bfa9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eUawxdfhNQ",
        "colab_type": "code",
        "outputId": "d1c3c0f4-7472-4f85-d511-a70aa618ae85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-8POV67fysz",
        "colab_type": "code",
        "outputId": "86eb6db4-ff39-46b3-9fc9-f846d06b7145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHAwQYl4gq4P",
        "colab_type": "code",
        "outputId": "b1722164-8687-473a-aac8-ce801b2f8aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!pip install gsheets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gsheets\n",
            "  Downloading https://files.pythonhosted.org/packages/96/44/8e6cefa0750b9594092640e044cbfbff8c5869b00691c5b996541fec7712/gsheets-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from gsheets) (1.7.11)\n",
            "Requirement already satisfied: oauth2client>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gsheets) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->gsheets) (0.0.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->gsheets) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->gsheets) (1.12.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->gsheets) (1.7.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->gsheets) (3.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=1.5.0->gsheets) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=1.5.0->gsheets) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=1.5.0->gsheets) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client->gsheets) (45.2.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client->gsheets) (3.1.1)\n",
            "Installing collected packages: gsheets\n",
            "Successfully installed gsheets-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKMcmuHohCT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80aWDVtLhTWE",
        "colab_type": "code",
        "outputId": "0a91b240-4c41-460f-cc2a-df7d6f9b167d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1nJ9D7k4kZsim42WeyZU9PiAB5pGLzfVS0OzmnGyjVnI/edit#gid=1091451249')\n",
        "print(wb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Spreadsheet 'NPS comments' id:1nJ9D7k4kZsim42WeyZU9PiAB5pGLzfVS0OzmnGyjVnI>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLyC1Bp5hcJd",
        "colab_type": "code",
        "outputId": "b802c84a-6bb9-4c7f-cc26-ad4b5a0e52dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sheet = wb.worksheet('NPS comments')\n",
        "print(sheet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Worksheet 'NPS comments' id:1091451249>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OrWItpchvhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = sheet.get_all_values()\n",
        "df = pd.DataFrame(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i344ky1siJw4",
        "colab_type": "text"
      },
      "source": [
        "#Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVJz3SoAiMX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df.columns = df.iloc[0] #place gsheet headlines on column\n",
        "df = df.iloc[1:] # remove gsheet headlines\n",
        "df = df.iloc[:, np.r_[3,8:19]] # get relevant columns only"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz6CqBPCwrct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove blanks\n",
        "df.replace(\" \",0, inplace=True)\n",
        "df.replace(\"\",0, inplace=True)\n",
        "df.iloc[:, 1:] = df.iloc[:, 1:].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvu8o17-R0R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop unlabled rows\n",
        "df['labled'] = df.iloc[:,1:].sum(axis=1,skipna =True) \n",
        "\n",
        "df.drop(df[df.labled == 0.0].index, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFXUxPEDojVb",
        "colab_type": "text"
      },
      "source": [
        "Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ueH4ATorqO",
        "colab_type": "code",
        "outputId": "fa8657ff-ca54-47e0-bead-cba187d385db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146,
          "referenced_widgets": [
            "0b1a325055db46e0a921b2743f9b16f5",
            "a549297ef14143438119da1cde91da0e",
            "6d5069a6a03f42e1a8fc5863ff2a90de",
            "0336080f72bb47b8aa4b4a3880fafc8a",
            "57d920cec519442b84d980632502520a",
            "644d5ffcb373492f98fbe5751f1ccc4f",
            "d5ec939b26ca46a8b634ee58f01ca4b1",
            "ff181e0d95cd4a1a9a6bd495f4d404d1"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b1a325055db46e0a921b2743f9b16f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i15sHDCI5X0t",
        "colab_type": "text"
      },
      "source": [
        "Comments and labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smn2aU1xox7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.FEEDBACK.values   # load feedbacks to numppy array\n",
        "#labels = df.missing_feature.values.astype(int) \n",
        "labels = df.iloc[:,1:-1].values.astype(np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAgFWZyw8EAR",
        "colab_type": "code",
        "outputId": "2aba4562-112c-4767-eaaa-51d4b366180b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "labels ,sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [1, 0, 1, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 1, 0, ..., 0, 0, 0],\n",
              "        [1, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array(['Excellent',\n",
              "        'This scheduling software is simple to use, I love the wordpress plugin which makes the whole process look nice on a website, and it helps give potential clients an easy way to contact your company or yourself. \\n\\nKeep up the good work and thank you for building tools everyone can use.',\n",
              "        'the system works as it should with simple proceedures',\n",
              "        'I have had great experience', \"It doesn't work well on mobile\",\n",
              "        'So-so UI', 'I am pleased with what I have to this point.',\n",
              "        'Overall the app is very helpful with great features. One suggestion: The text messaging campaign should have the ability to import contacts from mobile phone',\n",
              "        'I have been pleased overall with vCita.  Serves my purposes very well.  My only complaint is that the version I use will not send text reminders to clients that sign up for a campus visit.  Would be nice to have basic text service.',\n",
              "        'Very user-friendly platform and affordable.',\n",
              "        'I find it difficult to navigate', 'I love the system',\n",
              "        'Love the all in one functionality of the software. My clients feel like they are receiving a 5-star experience from the beginning of the process. This qualifies service charges and validates the viability of my business',\n",
              "        \"I really like you but you can't offer everything I would like!\",\n",
              "        'It needs one more functionality.  That is an easily visible link options for Google and other calendars. I have called about this several times before as this feature is very popular with webinar sign ups and some other appointment schedulers.  This would replace downloading the file, then clicking on it to attach to a calendar.',\n",
              "        'vcita does everything i need',\n",
              "        'The first nterface is cumbersome. Too many times clients have been able to make appointments during times when they should not have been able to do so. The price is too high. VCita does not have capabilities n cessait for medical billing and charting.',\n",
              "        'few basic items are more work than necessary \\ngreat program, but some things could be more user friendly like your mobile app',\n",
              "        'You are missing the Proposal piece of the CRM. It would be perfect with the ability to create proposals such as NiftyQuoter. With NiftyQuoter, I can just create proposals but cannot add a payment method nor track anything other than proposals.\\n\\nAlso, the plug in for the Wix site takes 6-10 seconds to load each time. Example www.premiercertificationservices.com',\n",
              "        \"vCita has served me well for a few years now. It's like having a very capable and accurate receptionist, and has greatly improved my professional appearance. It's so great to have everything in one place, including my service offerings and prices. Perhaps most importantly- vCita has resolved the awkward bill collection situations that were driving me crazy. I went from having an average of about 6 outstanding bills at any time, to having ALL invoices paid at ALL times! Beyond that, I now collect payment for certain services BEFORE the appointment. This is a huge value for me as a small business owner- saving me time, energy and greatly reduces stress. Thank you vCita!\",\n",
              "        'חסרות לי כמה אפשרויות קטנות שישפרו את ההתנהלות השוטפת של מערכת ההזמנות',\n",
              "        \"It's hard to sync with gmail and everything else.\",\n",
              "        'Very easy to use and gives us a professional look.',\n",
              "        'Love this App', 'love it',\n",
              "        \"It didn't blend easily to my IOS calendar.  There was a time error since I'm in Atlantic time...when the Eastern time changed...\",\n",
              "        'The platform has been consistent and reliable. It helps me streamline my efforts with simplicity',\n",
              "        'Lots of amazing features to grow business and sustain clients',\n",
              "        'your best',\n",
              "        \"vcita's plugin no longer working with Wordpress Gutenberg\",\n",
              "        'I wish we can show the service picture more clearly and sometimes when I edit things, it freezes. Hope you can update those and would give 10.',\n",
              "        \"sometimes this e-mail app does not work that we can't even send messages or vice versa.\",\n",
              "        \"I'm still learning about you, but have found it useful.\",\n",
              "        'Your app is crashing my website. It was down couple of times and cost me a lot to fix it. Please update it!',\n",
              "        'COMPLICATED AND CONTACT OF CLIENTS',\n",
              "        'it does what it supposed to', 'excellent app',\n",
              "        'Many times I have trouble syncing.',\n",
              "        'Love your product, price, attitude and service! Quadfecta!',\n",
              "        'Excellent software-user friendly and reliable!',\n",
              "        'it is not what I need', 'It is simple and practical',\n",
              "        'I wish cvita tried to do less. I know that sounds strange, but I like the appointment setting but the attempts to expand into other services are bothersome to me.',\n",
              "        'difficult and inconsistent', 'me gusta',\n",
              "        'Because the service has been excellent for the past couple of times that I have been using. Sure there are areas to improve, but for me, I would recommend Vcita to anyone.',\n",
              "        'Integrated widgets could be better visually (aesthetics). I would like to also be able to customize the way customer information is presented in my Client folders in order to make the most pertinent info for my business as visible as possible (increase size, rearrange).',\n",
              "        'works very good for client to business communication',\n",
              "        \"1. Customers not receiving emails when I replied to a message\\n2. IOS app (up-to-date iphone 7) crashes frequently. I'm not able to see what I'm typing while replying to a message.\",\n",
              "        \"It has been a very easy system for clients to use, and being able to customize the settings for notification, etc. has been such a lifesaver!  No one can forget an appointment, and it's an easy reference to reach someone with the info in the calendar.\",\n",
              "        'I like the operation',\n",
              "        'There needs to be a message response for clients to write no and I think maybe a section to block some ppl from booking',\n",
              "        'I like it', 'it is really an amazing service',\n",
              "        'Elegant, easy-to-use design,',\n",
              "        \"I only use it as contact page for a website, so, I'm not using all of it's benefits, but they are not needed for my application\",\n",
              "        'Still having difficulty with navigating through the site.',\n",
              "        \"There are some features missing like individual client info download and CRM client list download. Also, support doesn't follow up with emails. I used to be able to chat with support and it seems that feature is now disabled?\",\n",
              "        'Easy to use great features',\n",
              "        \"Group client communicationneeds work. And I wish client accounts had the option to associate more than one name with them. For me, the person paying for my services is usually not the one receiving them. It's usually parents paying for their kids to work with me.\",\n",
              "        'I love your service', 'Ease and access.', 'I love it.',\n",
              "        'Vcita is a friendly user and affordable for small business.',\n",
              "        'I am 100% happy with the results.  The Risk vs Reward has paid dividends in spades.  \\n\\nSincerely,\\nRobert Stone\\nMrTaxes.ca Inc.',\n",
              "        'I like vCita but have not had an opportunity to use it much since my business is not currently growing. I want to use it more.',\n",
              "        'My message was not delivered to me by a client who just called indicating that they submitted a contact request through this program',\n",
              "        'Can be too tricky. Needs better reporting. Overall is good.',\n",
              "        'it is the best scheduling app',\n",
              "        'I enjoy this service. It helps me to increase my productivity.',\n",
              "        'Not developing wanted features quickly enough.',\n",
              "        'vCita is very comprehensive, user-friendly, and affordable.  Keep up the great work!',\n",
              "        \"Vcita is not, yet, as comprehensive as I'd like it to be. It's difficult to do all of my business on Vcita because it is based on appointments only. I'd like to be able to sell a program and arrange appointments as needed.\",\n",
              "        'Love it!',\n",
              "        'This product runs smooth, looks professional and does what I need it to do!',\n",
              "        '1. I love it.\\n2. My clients love it.\\n3. I already recommend it.',\n",
              "        'Very good...missing the ability to allow clients to register for multiple sessions at once.',\n",
              "        'I love the platform. Very useful', 'You guys rock! :-))',\n",
              "        'It’s not really intuitive to use. You still can’t send multiple docs in one message',\n",
              "        'I love that appointment reminders automatically go out and that I can request payment at the time of scheduling. It seems that I get paid more readily and without ever having to pester a client for payment. I also like that the credit card/paypal transactions require no time and effort on my part the great majority of the time. All correspondence that my clients see if very professional! I feel that vcita gives my business professional validity. Thanks so much!',\n",
              "        \"Just started using it. Not sure if it's going to cover my needs!\",\n",
              "        'The platform is easy to use.. I wish you would add more payment gateways',\n",
              "        'easy and priced right',\n",
              "        \"I've been finding it useful for getting people to contact me about my classes before leaving my website\",\n",
              "        'Great services. The platform is easy to use and it helps me to be more efficient in my business.',\n",
              "        'Ease of use with great features',\n",
              "        'Impressed with the features, but still a little clunky',\n",
              "        'Well... it works ok... just not sure for all business this is needed.',\n",
              "        \"The calendar being ss important as it is, doesn't appear on my phone interface even though it previously did. It is an important function for my business. I have to search for it.\",\n",
              "        'Vcita makes creating invoices and keeping contacts simple, convenient, and clean.',\n",
              "        'its an integrated solution and fairly easy to navigate',\n",
              "        'convenient, but still not intuitive',\n",
              "        'The scheduling tool is efficient for my small business needs and it provides my professional look, which my clients love!',\n",
              "        'Its easy to use, has a mobile app and i can communicate with clients on the fly, in real time.',\n",
              "        'Like the service',\n",
              "        'There are issues with your program that my website company can not seem to straighten out.',\n",
              "        'Great CRM system and easy to use.', 'Love Vcita',\n",
              "        'Every aspect of the profession on line booking application is well thought out with 0 / no issues.  It makes a statement of professionalize to any clients or potential clients.  It is also very easy for someone to use.  Thanks for providing a 5 star product.  Dina Dee Paige  consultdee@gmail.com 1 416 828 8680',\n",
              "        'Because this app has simplified appointments for me. I love the convenience',\n",
              "        'hard to use calendar with other calendars. not enough useful resources to learn the product effectively...too much learning curve to get started',\n",
              "        'Like it',\n",
              "        'The mobile user experience, for me, is flawed, particularly the notification or lack of. \\n\\nCustomers sometimes reply to the emails direct and when they do, attachments get stripped. This is a problem, for me. \\n\\nA few other small things, fix those and I’m giving it a 10',\n",
              "        \"#1 I don't use the service to the extent it is intended. \\n#2 You charge me without any advance notice. Suddenly $150 charge appears on my cc.\",\n",
              "        'VCita has pros and cons. There are aspects that are amazing - ease of use, customer service, layout. There are an increasing number of challenges as the platform has grown. Some things simply don’t make sense or require laborious workarounds.',\n",
              "        'Excellent easy to use service!',\n",
              "        \"Easy to use; can keep track of all prospects and clients' communication; super-cool and professional invoicing.  Excellent form builder for service application forms or contact forms... and more :)\",\n",
              "        'Great value for money, very easy to use. Works on mobile platform and on PC. Integrates well with Outlook and Gmail calendars.',\n",
              "        'I love your platform. My business depends upon it now.',\n",
              "        'Easy to use. Convenient.',\n",
              "        'The calendar consistently schedules people during unavailable times.',\n",
              "        'Great system!! easy to use', 'useful',\n",
              "        'I love the online calendar and conversation features.',\n",
              "        \"I'm really thankful for this service. The mobile app has come a long way but can still use improvements in speed as I often don't have WiFi access.\",\n",
              "        'Like the app',\n",
              "        'it\\'s just \"clunky\".  Doesn\\'t save login information, when MOST even \"sensitive\" websites do.  Slow.',\n",
              "        'cant edit the colours on home page/live site',\n",
              "        'Too expensive...Slow support...Buggy',\n",
              "        'Very reliable software, easy to use',\n",
              "        'Still a little confused on how to use everything',\n",
              "        'Organizes my ENTIRE client base!',\n",
              "        'The mobile app is not great.\\n\\nI would love to be able to edit the settings on the mobile app.\\n\\nAnd also I would love to be able to make a booking like a customer with the automatic calander availability without using a customer link.\\n\\n\\nAlso the app is web based which means you cannot do anything off-line.',\n",
              "        'There is a lot of room for improvement on basic setup of clients, payments and configuration setups. Its not easy and there is a steep learning curve in some areas.',\n",
              "        'easy to use and cost effective',\n",
              "        \"Would've been a 10 but your mobile app needs work.\",\n",
              "        'Lately we have had some syncing issues leading to some appointments that needed to be rescheduled.',\n",
              "        'vCita pays for itself by allowing clients the ease of paying from where ever and however they chose.',\n",
              "        'Best calendering tool I have found that integrates with the Apple iOS ecosystem!!!!!',\n",
              "        'Our office loves vCita, we have not had any forgotten appointments,',\n",
              "        'Love it, affordable and easy to use'], dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNwv6FVYpvKp",
        "colab_type": "text"
      },
      "source": [
        "Examine Tokenized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQmG-zfprAK",
        "colab_type": "code",
        "outputId": "63d9025f-8a86-43f0-eff4-13af76992110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[18])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[18]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[18])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  You are missing the Proposal piece of the CRM. It would be perfect with the ability to create proposals such as NiftyQuoter. With NiftyQuoter, I can just create proposals but cannot add a payment method nor track anything other than proposals.\n",
            "\n",
            "Also, the plug in for the Wix site takes 6-10 seconds to load each time. Example www.premiercertificationservices.com\n",
            "Tokenized:  ['you', 'are', 'missing', 'the', 'proposal', 'piece', 'of', 'the', 'cr', '##m', '.', 'it', 'would', 'be', 'perfect', 'with', 'the', 'ability', 'to', 'create', 'proposals', 'such', 'as', 'ni', '##ft', '##y', '##qu', '##ote', '##r', '.', 'with', 'ni', '##ft', '##y', '##qu', '##ote', '##r', ',', 'i', 'can', 'just', 'create', 'proposals', 'but', 'cannot', 'add', 'a', 'payment', 'method', 'nor', 'track', 'anything', 'other', 'than', 'proposals', '.', 'also', ',', 'the', 'plug', 'in', 'for', 'the', 'wi', '##x', 'site', 'takes', '6', '-', '10', 'seconds', 'to', 'load', 'each', 'time', '.', 'example', 'www', '.', 'premier', '##cer', '##ti', '##fication', '##ser', '##vic', '##es', '.', 'com']\n",
            "Token IDs:  [2017, 2024, 4394, 1996, 6378, 3538, 1997, 1996, 13675, 2213, 1012, 2009, 2052, 2022, 3819, 2007, 1996, 3754, 2000, 3443, 10340, 2107, 2004, 9152, 6199, 2100, 28940, 12184, 2099, 1012, 2007, 9152, 6199, 2100, 28940, 12184, 2099, 1010, 1045, 2064, 2074, 3443, 10340, 2021, 3685, 5587, 1037, 7909, 4118, 4496, 2650, 2505, 2060, 2084, 10340, 1012, 2036, 1010, 1996, 13354, 1999, 2005, 1996, 15536, 2595, 2609, 3138, 1020, 1011, 2184, 3823, 2000, 7170, 2169, 2051, 1012, 2742, 7479, 1012, 4239, 17119, 3775, 10803, 8043, 7903, 2229, 1012, 4012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upP8txBR13yJ",
        "colab_type": "text"
      },
      "source": [
        "Add CLS token for beginnings and SEP to end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYsSQf6O1mwR",
        "colab_type": "code",
        "outputId": "345fa63e-f8f4-4efa-d3a2-b54557f09fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Excellent\n",
            "Token IDs: [101, 6581, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwKiz05r2jHz",
        "colab_type": "text"
      },
      "source": [
        "Get maximum length and pad every sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juu2LQfi1_0x",
        "colab_type": "code",
        "outputId": "b15caef4-3d2c-4e19-e4ab-d42c5f26da6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids])) # MAX length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyXIv8YJ2Pk8",
        "colab_type": "code",
        "outputId": "e88a3acc-3637-48d6-c447-57d05c5f6c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 145\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 145 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbVUz_7v4xaB",
        "colab_type": "text"
      },
      "source": [
        "Add Attention masks to identify what is actuall word and what is a pad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STCm34Bi3tf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTzdh39M467J",
        "colab_type": "text"
      },
      "source": [
        "Training & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37E1ahtZ49L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.3)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFtFi0iJ5EdG",
        "colab_type": "text"
      },
      "source": [
        "Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLqXAodJfS-",
        "colab_type": "code",
        "outputId": "a96ba8b0-fe45-4b4f-8a87-dcbc155f2502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "validation_inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 101, 1045, 2293, ...,    0,    0,    0],\n",
              "       [ 101, 2293, 1996, ...,    0,    0,    0],\n",
              "       [ 101, 2524, 2000, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 101, 1045, 2572, ...,    0,    0,    0],\n",
              "       [ 101, 3733, 2000, ...,    0,    0,    0],\n",
              "       [ 101, 1045, 2293, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYu6-fHc5EzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUihnfRgBDDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "own5cnpuEnsb",
        "colab_type": "code",
        "outputId": "a65487a7-dfc9-4c31-c335-09e76a43445b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "for batch in enumerate(train_dataloader):\n",
        "  print(batch[1][2].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 11])\n",
            "torch.Size([32, 11])\n",
            "torch.Size([28, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD7d-qy7-wqo",
        "colab_type": "text"
      },
      "source": [
        "# Constructing The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHiiX2WAulTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig , BertPreTrainedModel ,BertModel\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "\"\"\",\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 11, # The number of output labels--2 for binary classification.\n",
        "                     # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\"\"\"\n",
        "\n",
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels = 11):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "        #self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output[1])\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels).type(torch.float), \n",
        "                            labels.view(-1, self.num_labels).type(torch.float))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqcdCyqkziiI",
        "colab_type": "code",
        "outputId": "1759a6b5-2098-4bc8-c54e-8eab91d1c657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7168abd443dc4939bb96d33424c6a501",
            "f1f3e3bd66194c2898e63dbe4431bede",
            "f62051068c4d490f9d10dd376b5e8d26",
            "30f8a1916f0f4c25b418ec62bd40d681",
            "2b896661e1a14ad78959e1288feb8f32",
            "962ae8075b074fb28cc97eba94f64da5",
            "372fa204063e41f788935ffc9bfbe436",
            "9367c8a112464ab28a02a7a6bacf1a1a",
            "7a0992b00178475fa91388992d81113f",
            "7636475c736b4ece803783f8240ab526",
            "51377bf609884e08aa4f756ff38a9e65",
            "9c416fc1723f4aba988da18fd0ac6793",
            "e1d78937e7de4573a513e0caebf883f2",
            "15535af5f77f40f59e8f6603074dd79f",
            "fc06914a72fc44c49d1c81e16c97bfe1",
            "e10739852ae44349add845cd64374cc0"
          ]
        }
      },
      "source": [
        "\n",
        "num_labels = 11 \n",
        "model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = num_labels,\n",
        "                                                                output_hidden_states=True)\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7168abd443dc4939bb96d33424c6a501",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a0992b00178475fa91388992d81113f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1L5XobP_YuD",
        "colab_type": "code",
        "outputId": "b166d010-2bd7-4c59-a828-42aaeeed8036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (11, 768)\n",
            "classifier.bias                                                (11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMAFnG-hAH2o",
        "colab_type": "text"
      },
      "source": [
        "Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kzTRKuVAKRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzj_XLv8AQG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 6\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsUJoGRABPox",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMgrZFDcBYT4",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTtx1gofBRPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "\"\"\"def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(preds)\n",
        "    print(len(pred_flat))\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\"\"\"\n",
        "def flat_accuracy(preds, labels, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: preds = torch.from_numpy(preds).sigmoid()\n",
        "    #print((preds))\n",
        "    #print(torch.from_numpy(labels))\n",
        "    #print(np.mean(((preds>thresh)==torch.from_numpy(labels)).float().cpu().numpy(), axis=0))\n",
        "    return np.mean(((preds>thresh)==torch.from_numpy(labels)).float().cpu().numpy(), axis=0).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB0qYSf1BamU",
        "colab_type": "text"
      },
      "source": [
        "Helper function for formatting elapsed times.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MVWSWoCBcPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0N3bquyBmDK",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Rf-P_8BoHa",
        "colab_type": "code",
        "outputId": "b03ca377-1f0d-409d-ab7c-0aa6aba11c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        outputs = outputs.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(outputs, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:00:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}